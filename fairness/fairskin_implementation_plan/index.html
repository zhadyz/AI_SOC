
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Research-driven AI system for equitable dermatological diagnosis across all skin tones">
      
      
        <meta name="author" content="Jasmin Flores, Abdul Bari">
      
      
        <link rel="canonical" href="https://research.onyxlab.ai/fairness/fairskin_implementation_plan/">
      
      
        <link rel="prev" href="../circle_implementation/">
      
      
        <link rel="next" href="../fairdisco_training_guide/">
      
      
      <link rel="icon" href="../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>FairSkin Implementation Plan - Fairness in Skin Cancer Detection</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CSF+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"SF Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../stylesheets/custom.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config",""),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#fairskin-diffusion-augmentation-implementation-plan" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Fairness in Skin Cancer Detection" class="md-header__button md-logo" aria-label="Fairness in Skin Cancer Detection" data-md-component="logo">
      
  <img src="../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Fairness in Skin Cancer Detection
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              FairSkin Implementation Plan
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/zhadyz/fairness-skin-cancer-detection" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    zhadyz/fairness-skin-cancer-detection
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../quickstart/" class="md-tabs__link">
          
  
  
  Getting Started

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../architecture/" class="md-tabs__link">
          
  
  
  Architecture

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../fairdisco_training_guide/" class="md-tabs__link">
          
  
  
  Training & Experiments

        </a>
      </li>
    
  

    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../docker_guide/" class="md-tabs__link">
          
  
  
  Technical Guides

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../synthetic_augmentation/" class="md-tabs__link">
          
  
  
  Research & Innovation

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../phase4_production_hardening/" class="md-tabs__link">
          
  
  
  Production

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../about/authors/" class="md-tabs__link">
          
  
  
  About

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Fairness in Skin Cancer Detection" class="md-nav__button md-logo" aria-label="Fairness in Skin Cancer Detection" data-md-component="logo">
      
  <img src="../assets/logo.png" alt="logo">

    </a>
    Fairness in Skin Cancer Detection
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/zhadyz/fairness-skin-cancer-detection" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    zhadyz/fairness-skin-cancer-detection
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Getting Started
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Getting Started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../quickstart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Quick Start
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../environment_setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Environment Setup
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dataset_access_log/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Dataset Access
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ham10000_integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    HAM10000 Integration
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Architecture
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Architecture
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../architecture/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    System Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fairdisco_architecture/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FairDisCo Implementation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../circle_implementation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    CIRCLe Implementation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    FairSkin Implementation Plan
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    FairSkin Implementation Plan
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#executive-summary" class="md-nav__link">
    <span class="md-ellipsis">
      Executive Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-architecture-overview" class="md-nav__link">
    <span class="md-ellipsis">
      1. Architecture Overview
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Architecture Overview">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-base-model-stable-diffusion-v15" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 Base Model: Stable Diffusion v1.5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-fine-tuning-strategy-lora-textual-inversion" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 Fine-Tuning Strategy: LoRA + Textual Inversion
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-conditioning-mechanism" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 Conditioning Mechanism
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-training-requirements" class="md-nav__link">
    <span class="md-ellipsis">
      2. Training Requirements
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Training Requirements">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-dataset-specification" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Dataset Specification
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-gpu-requirements" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 GPU Requirements
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-hyperparameters-optimized-from-literature" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 Hyperparameters (Optimized from Literature)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-inference-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      3. Inference Pipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Inference Pipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-generation-protocol" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Generation Protocol
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-quality-validation" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Quality Validation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-integration-with-training-loop" class="md-nav__link">
    <span class="md-ellipsis">
      4. Integration with Training Loop
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Integration with Training Loop">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-synthetic-real-data-mixing" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 Synthetic + Real Data Mixing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-training-protocol" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 Training Protocol
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-implementation-timeline" class="md-nav__link">
    <span class="md-ellipsis">
      5. Implementation Timeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Implementation Timeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#week-1-setup-dataset-preparation" class="md-nav__link">
    <span class="md-ellipsis">
      Week 1: Setup &amp; Dataset Preparation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#week-2-textual-inversion" class="md-nav__link">
    <span class="md-ellipsis">
      Week 2: Textual Inversion
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#week-3-4-lora-training" class="md-nav__link">
    <span class="md-ellipsis">
      Week 3-4: LoRA Training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#week-5-batch-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Week 5: Batch Generation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#week-6-integration-training" class="md-nav__link">
    <span class="md-ellipsis">
      Week 6: Integration &amp; Training
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-pre-trained-models-open-source-resources" class="md-nav__link">
    <span class="md-ellipsis">
      6. Pre-Trained Models &amp; Open-Source Resources
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Pre-Trained Models &amp; Open-Source Resources">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-available-checkpoints" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 Available Checkpoints
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62-alternative-architectures-future-work" class="md-nav__link">
    <span class="md-ellipsis">
      6.2 Alternative Architectures (Future Work)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-key-questions-answers" class="md-nav__link">
    <span class="md-ellipsis">
      7. Key Questions &amp; Answers
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Key Questions &amp; Answers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#q1-can-we-use-pre-trained-dermatology-diffusion-models" class="md-nav__link">
    <span class="md-ellipsis">
      Q1: Can we use pre-trained dermatology diffusion models?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q2-whats-the-minimum-viable-dataset-for-lora-training" class="md-nav__link">
    <span class="md-ellipsis">
      Q2: What's the minimum viable dataset for LoRA training?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q3-how-to-ensure-synthetic-quality-fid-20-lpips-01" class="md-nav__link">
    <span class="md-ellipsis">
      Q3: How to ensure synthetic quality (FID &lt;20, LPIPS &lt;0.1)?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q4-pre-generate-60k-images-or-on-the-fly-during-training" class="md-nav__link">
    <span class="md-ellipsis">
      Q4: Pre-generate 60k images or on-the-fly during training?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-risk-mitigation" class="md-nav__link">
    <span class="md-ellipsis">
      8. Risk Mitigation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. Risk Mitigation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#risk-1-low-synthetic-quality-fid-30" class="md-nav__link">
    <span class="md-ellipsis">
      Risk 1: Low Synthetic Quality (FID &gt;30)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#risk-2-mode-collapse-all-fst-vi-images-look-identical" class="md-nav__link">
    <span class="md-ellipsis">
      Risk 2: Mode Collapse (All FST VI Images Look Identical)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#risk-3-memorization-synthetic-images-identical-to-training-data" class="md-nav__link">
    <span class="md-ellipsis">
      Risk 3: Memorization (Synthetic Images Identical to Training Data)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#risk-4-domain-shift-classifier-fails-on-synthetic-images" class="md-nav__link">
    <span class="md-ellipsis">
      Risk 4: Domain Shift (Classifier Fails on Synthetic Images)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#risk-5-ethical-concerns-synthetic-medical-data" class="md-nav__link">
    <span class="md-ellipsis">
      Risk 5: Ethical Concerns (Synthetic Medical Data)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-success-criteria" class="md-nav__link">
    <span class="md-ellipsis">
      9. Success Criteria
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Success Criteria">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#technical-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      Technical Metrics
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fairness-impact" class="md-nav__link">
    <span class="md-ellipsis">
      Fairness Impact
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qualitative-validation" class="md-nav__link">
    <span class="md-ellipsis">
      Qualitative Validation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#operational" class="md-nav__link">
    <span class="md-ellipsis">
      Operational
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-references" class="md-nav__link">
    <span class="md-ellipsis">
      10. References
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Training & Experiments
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Training & Experiments
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Training Guides
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            Training Guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fairdisco_training_guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FairDisCo Training
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../circle_training_guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    CIRCLe Training
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fairskin_usage_guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FairSkin Usage
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../experiment_tracking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Experiment Tracking
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../baseline_results/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Baseline Results
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Technical Guides
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Technical Guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../docker_guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Docker Guide
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../testing_guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Testing Guide
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../code_quality_standards/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Code Quality Standards
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fst_annotation_protocol/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FST Annotation Protocol
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Research & Innovation
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Research & Innovation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../synthetic_augmentation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Synthetic Augmentation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open_source_fairness_code/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Open Source Fairness Code
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fairness_computational_costs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Fairness Computational Costs
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Production
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Production
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../phase4_production_hardening/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Phase 4 Production Hardening
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../roadmap/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Implementation Roadmap
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    About
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            About
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../about/authors/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Authors & Acknowledgments
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../about/license/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    License
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../about/citation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Citation
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#executive-summary" class="md-nav__link">
    <span class="md-ellipsis">
      Executive Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-architecture-overview" class="md-nav__link">
    <span class="md-ellipsis">
      1. Architecture Overview
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Architecture Overview">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-base-model-stable-diffusion-v15" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 Base Model: Stable Diffusion v1.5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-fine-tuning-strategy-lora-textual-inversion" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 Fine-Tuning Strategy: LoRA + Textual Inversion
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-conditioning-mechanism" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 Conditioning Mechanism
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-training-requirements" class="md-nav__link">
    <span class="md-ellipsis">
      2. Training Requirements
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Training Requirements">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-dataset-specification" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Dataset Specification
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-gpu-requirements" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 GPU Requirements
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-hyperparameters-optimized-from-literature" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 Hyperparameters (Optimized from Literature)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-inference-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      3. Inference Pipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Inference Pipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-generation-protocol" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Generation Protocol
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-quality-validation" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Quality Validation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-integration-with-training-loop" class="md-nav__link">
    <span class="md-ellipsis">
      4. Integration with Training Loop
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Integration with Training Loop">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-synthetic-real-data-mixing" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 Synthetic + Real Data Mixing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-training-protocol" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 Training Protocol
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-implementation-timeline" class="md-nav__link">
    <span class="md-ellipsis">
      5. Implementation Timeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Implementation Timeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#week-1-setup-dataset-preparation" class="md-nav__link">
    <span class="md-ellipsis">
      Week 1: Setup &amp; Dataset Preparation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#week-2-textual-inversion" class="md-nav__link">
    <span class="md-ellipsis">
      Week 2: Textual Inversion
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#week-3-4-lora-training" class="md-nav__link">
    <span class="md-ellipsis">
      Week 3-4: LoRA Training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#week-5-batch-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Week 5: Batch Generation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#week-6-integration-training" class="md-nav__link">
    <span class="md-ellipsis">
      Week 6: Integration &amp; Training
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-pre-trained-models-open-source-resources" class="md-nav__link">
    <span class="md-ellipsis">
      6. Pre-Trained Models &amp; Open-Source Resources
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Pre-Trained Models &amp; Open-Source Resources">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-available-checkpoints" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 Available Checkpoints
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62-alternative-architectures-future-work" class="md-nav__link">
    <span class="md-ellipsis">
      6.2 Alternative Architectures (Future Work)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-key-questions-answers" class="md-nav__link">
    <span class="md-ellipsis">
      7. Key Questions &amp; Answers
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Key Questions &amp; Answers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#q1-can-we-use-pre-trained-dermatology-diffusion-models" class="md-nav__link">
    <span class="md-ellipsis">
      Q1: Can we use pre-trained dermatology diffusion models?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q2-whats-the-minimum-viable-dataset-for-lora-training" class="md-nav__link">
    <span class="md-ellipsis">
      Q2: What's the minimum viable dataset for LoRA training?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q3-how-to-ensure-synthetic-quality-fid-20-lpips-01" class="md-nav__link">
    <span class="md-ellipsis">
      Q3: How to ensure synthetic quality (FID &lt;20, LPIPS &lt;0.1)?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q4-pre-generate-60k-images-or-on-the-fly-during-training" class="md-nav__link">
    <span class="md-ellipsis">
      Q4: Pre-generate 60k images or on-the-fly during training?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-risk-mitigation" class="md-nav__link">
    <span class="md-ellipsis">
      8. Risk Mitigation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. Risk Mitigation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#risk-1-low-synthetic-quality-fid-30" class="md-nav__link">
    <span class="md-ellipsis">
      Risk 1: Low Synthetic Quality (FID &gt;30)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#risk-2-mode-collapse-all-fst-vi-images-look-identical" class="md-nav__link">
    <span class="md-ellipsis">
      Risk 2: Mode Collapse (All FST VI Images Look Identical)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#risk-3-memorization-synthetic-images-identical-to-training-data" class="md-nav__link">
    <span class="md-ellipsis">
      Risk 3: Memorization (Synthetic Images Identical to Training Data)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#risk-4-domain-shift-classifier-fails-on-synthetic-images" class="md-nav__link">
    <span class="md-ellipsis">
      Risk 4: Domain Shift (Classifier Fails on Synthetic Images)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#risk-5-ethical-concerns-synthetic-medical-data" class="md-nav__link">
    <span class="md-ellipsis">
      Risk 5: Ethical Concerns (Synthetic Medical Data)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-success-criteria" class="md-nav__link">
    <span class="md-ellipsis">
      9. Success Criteria
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Success Criteria">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#technical-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      Technical Metrics
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fairness-impact" class="md-nav__link">
    <span class="md-ellipsis">
      Fairness Impact
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qualitative-validation" class="md-nav__link">
    <span class="md-ellipsis">
      Qualitative Validation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#operational" class="md-nav__link">
    <span class="md-ellipsis">
      Operational
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-references" class="md-nav__link">
    <span class="md-ellipsis">
      10. References
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="fairskin-diffusion-augmentation-implementation-plan">FairSkin Diffusion Augmentation: Implementation Plan<a class="headerlink" href="#fairskin-diffusion-augmentation-implementation-plan" title="Permanent link">&para;</a></h1>
<h2 id="executive-summary">Executive Summary<a class="headerlink" href="#executive-summary" title="Permanent link">&para;</a></h2>
<p>FairSkin is a diffusion-based data augmentation technique that generates synthetic skin lesion images with balanced Fitzpatrick Skin Type (FST) representation. This document provides a comprehensive implementation plan including architecture details, training requirements, integration strategy, and quality validation protocols.</p>
<p><strong>Expected Impact</strong>: +18-21% AUROC improvement for FST V-VI groups (Ju et al., 2024)</p>
<hr />
<h2 id="1-architecture-overview">1. Architecture Overview<a class="headerlink" href="#1-architecture-overview" title="Permanent link">&para;</a></h2>
<h3 id="11-base-model-stable-diffusion-v15">1.1 Base Model: Stable Diffusion v1.5<a class="headerlink" href="#11-base-model-stable-diffusion-v15" title="Permanent link">&para;</a></h3>
<p><strong>Foundation</strong>:
- Pre-trained Stable Diffusion v1.5 (CompVis/Stability AI)
- 860M parameters (U-Net: 860M, VAE: 83M, CLIP text encoder: 123M)
- Trained on LAION-5B (general domain images)</p>
<p><strong>Why Stable Diffusion</strong>:
- State-of-the-art image generation quality (FID &lt;20)
- Efficient inference (20-50 steps, 3-6s on RTX 3090)
- Extensive community support and tooling (Hugging Face Diffusers)
- Parameter-efficient fine-tuning via LoRA (Low-Rank Adaptation)</p>
<h3 id="12-fine-tuning-strategy-lora-textual-inversion">1.2 Fine-Tuning Strategy: LoRA + Textual Inversion<a class="headerlink" href="#12-fine-tuning-strategy-lora-textual-inversion" title="Permanent link">&para;</a></h3>
<p><strong>LoRA (Low-Rank Adaptation)</strong>:
- Freeze base Stable Diffusion weights (860M params)
- Train low-rank decomposition matrices: ΔW = BA (where B is rank×original_dim, A is original_dim×rank)
- Typical rank r=4-16 (reduces trainable params from 860M to ~3-10M)
- Only update cross-attention layers in U-Net (most semantically relevant)</p>
<p><strong>Textual Inversion</strong>:
- Learn new token embeddings for medical concepts
- Example tokens: <code>&lt;melanoma-FST-VI&gt;</code>, <code>&lt;nevus-FST-I&gt;</code>, <code>&lt;basal-cell-FST-IV&gt;</code>
- Embedding dimension: 768 (CLIP text encoder dimension)
- Freezes all weights except new token embeddings (~500K params)</p>
<p><strong>Combined Approach</strong> (from janet-sw/skin-diff):
1. Phase 1: Textual Inversion (find optimal token embeddings)
   - Train 1000-2000 steps (~2-4 hours on RTX 3090)
   - Validate: Can generate basic lesion concepts from text prompts
2. Phase 2: LoRA fine-tuning (adapt U-Net to medical domain)
   - Train 5000-10000 steps (~10-20 hours on RTX 3090)
   - Integrate new tokens learned in Phase 1
3. Phase 3: Joint refinement (optional)
   - Co-train both LoRA and token embeddings
   - 2000-5000 additional steps (~4-10 hours)</p>
<h3 id="13-conditioning-mechanism">1.3 Conditioning Mechanism<a class="headerlink" href="#13-conditioning-mechanism" title="Permanent link">&para;</a></h3>
<p><strong>Multi-Level Conditioning</strong>:
1. <strong>Text Prompt</strong> (primary):
   - Format: <code>"A dermoscopic image of {diagnosis} on Fitzpatrick skin type {FST}, high quality medical photograph"</code>
   - Example: <code>"A dermoscopic image of melanoma on Fitzpatrick skin type VI, high quality medical photograph"</code></p>
<ol>
<li><strong>Class Labels</strong> (optional, via classifier-free guidance):</li>
<li>Diagnosis class (7 classes: MEL, NV, BCC, AK, BKL, DF, VASC)</li>
<li>FST class (6 classes: I-VI)</li>
<li>
<p>Encoded as additional conditioning vectors</p>
</li>
<li>
<p><strong>Image Conditioning</strong> (for controlled generation):</p>
</li>
<li>Reference image from minority group (FST V-VI)</li>
<li>Extract CLIP embeddings, add to text embeddings</li>
<li>Enables style transfer: "Generate MEL with texture from this image"</li>
</ol>
<p><strong>Three-Level Resampling</strong> (Ju et al., 2024):
1. <strong>Balanced Sampling</strong>: Oversample minority FST classes during training
   - FST I-III: 40% of batches
   - FST IV: 20% of batches
   - FST V-VI: 40% of batches (vs &lt;5% in original datasets)</p>
<ol>
<li><strong>Class Diversity Loss</strong>: Add auxiliary loss to encourage intra-class diversity</li>
<li>L_diversity = -log(1/N × Σ cosine_distance(embedding_i, embedding_j))</li>
<li>
<p>Penalizes mode collapse (all FST VI images looking identical)</p>
</li>
<li>
<p><strong>Imbalance-Aware Augmentation</strong>: During classifier training, dynamically weight synthetic vs real</p>
</li>
<li>FST I-III: 20% synthetic, 80% real (abundant data)</li>
<li>FST V-VI: 80% synthetic, 20% real (scarce data)</li>
</ol>
<hr />
<h2 id="2-training-requirements">2. Training Requirements<a class="headerlink" href="#2-training-requirements" title="Permanent link">&para;</a></h2>
<h3 id="21-dataset-specification">2.1 Dataset Specification<a class="headerlink" href="#21-dataset-specification" title="Permanent link">&para;</a></h3>
<p><strong>Minimum Viable Dataset</strong>:
- Size: 500-1000 dermatology images (per diagnosis class)
- FST distribution: Minimum 100 images per FST class (150-200 preferred)
- Quality: High-resolution dermoscopic images (512x512 minimum, 1024x1024 preferred)
- Annotations:
  - Diagnosis label (7 classes: MEL, NV, BCC, AK, BKL, DF, VASC)
  - FST label (I-VI, dual annotation preferred)
  - Optional: ITA (Individual Typology Angle) for validation</p>
<p><strong>Recommended Training Datasets</strong>:
1. <strong>Fitzpatrick17k</strong>: 16,577 images, ~8% FST V-VI
   - Use ALL images for textual inversion (broad concept learning)
   - Use FST V-VI subset for LoRA fine-tuning (focus on minority groups)</p>
<ol>
<li><strong>DDI (Stanford)</strong>: 656 images, 34% FST V-VI (gold standard quality)</li>
<li>Primary dataset for LoRA fine-tuning</li>
<li>
<p>Clinician-annotated, biopsy-confirmed</p>
</li>
<li>
<p><strong>HAM10000</strong>: 10,015 images, &lt;5% FST V-VI (high quality, tone-imbalanced)</p>
</li>
<li>Use only for textual inversion (learn lesion morphology)</li>
<li>Do NOT use for LoRA (would bias toward light tones)</li>
</ol>
<p><strong>Data Preprocessing</strong>:
- Resize: 512x512 (Stable Diffusion v1.5 native resolution)
- Normalization: [0, 1] range (diffusion models trained on normalized images)
- Augmentation: ONLY for real data (horizontal flip, rotation, color jitter)
  - Do NOT augment during diffusion training (hurts generation quality)
- Hair removal: Apply automated hair removal (DullRazor algorithm)
  - Prevents model from learning "hair = dark skin" spurious correlation</p>
<h3 id="22-gpu-requirements">2.2 GPU Requirements<a class="headerlink" href="#22-gpu-requirements" title="Permanent link">&para;</a></h3>
<p><strong>Hardware Specifications</strong>:
- Minimum: 1x RTX 3090 (24GB VRAM)
- Recommended: 2x RTX 4090 (48GB total VRAM)
- Optimal: 4x A100 (160GB total VRAM, reduced training time by 4x)</p>
<p><strong>VRAM Breakdown</strong> (512x512 resolution, batch size 4):
- Model weights: 3.4GB (Stable Diffusion v1.5)
- LoRA adapters: 0.8GB (rank 16, all attention layers)
- Optimizer state (AdamW): 4.2GB (2x model params for momentum + variance)
- Activations (forward pass): 2.1GB per image × 4 = 8.4GB
- Gradient checkpointing: Reduces to 4.2GB (-50% VRAM, +20% time)
- <strong>Total: 16.8GB</strong> (fits on RTX 3090 with gradient checkpointing)</p>
<p><strong>Training Time Estimates</strong> (RTX 3090, 1000 training images):
- Textual Inversion: 2000 steps × 1.2s/step = 40 minutes
- LoRA Training: 10000 steps × 2.8s/step = 7.8 hours
- Joint Refinement: 3000 steps × 3.1s/step = 2.6 hours
- <strong>Total: ~12-14 hours</strong> (single GPU, sequential training)</p>
<p><strong>Multi-GPU Scaling</strong>:
- 2 GPUs: 6-7 hours (1.9x speedup, communication overhead)
- 4 GPUs: 3-4 hours (3.2x speedup)
- 8 GPUs: 2-3 hours (4.8x speedup, diminishing returns)</p>
<h3 id="23-hyperparameters-optimized-from-literature">2.3 Hyperparameters (Optimized from Literature)<a class="headerlink" href="#23-hyperparameters-optimized-from-literature" title="Permanent link">&para;</a></h3>
<p><strong>Textual Inversion</strong>:
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">5e-4</span>  <span class="c1"># Higher than LoRA (only ~500K params)</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="n">num_steps</span> <span class="o">=</span> <span class="mi">2000</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="n">gradient_accumulation</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Effective batch size: 8</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="n">lr_scheduler</span> <span class="o">=</span> <span class="s2">&quot;constant_with_warmup&quot;</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="n">warmup_steps</span> <span class="o">=</span> <span class="mi">100</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="n">optimizer</span> <span class="o">=</span> <span class="s2">&quot;AdamW&quot;</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">0.01</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="n">max_grad_norm</span> <span class="o">=</span> <span class="mf">1.0</span>
</span></code></pre></div></p>
<p><strong>LoRA Training</strong>:
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-4</span>  <span class="c1"># Lower than textual inversion (more params)</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="n">num_steps</span> <span class="o">=</span> <span class="mi">10000</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="n">gradient_accumulation</span> <span class="o">=</span> <span class="mi">2</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="n">lora_rank</span> <span class="o">=</span> <span class="mi">16</span>  <span class="c1"># Balance: 8 (underfits), 32 (overfits)</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="n">lora_alpha</span> <span class="o">=</span> <span class="mi">32</span>  <span class="c1"># Scaling factor (typically 2×rank)</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="n">lora_dropout</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Regularization</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a><span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;to_q&quot;</span><span class="p">,</span> <span class="s2">&quot;to_k&quot;</span><span class="p">,</span> <span class="s2">&quot;to_v&quot;</span><span class="p">,</span> <span class="s2">&quot;to_out&quot;</span><span class="p">]</span>  <span class="c1"># Cross-attention</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a><span class="n">lr_scheduler</span> <span class="o">=</span> <span class="s2">&quot;cosine_with_restarts&quot;</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a><span class="n">num_cycles</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># Escape local minima</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a><span class="n">optimizer</span> <span class="o">=</span> <span class="s2">&quot;AdamW&quot;</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a><span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">0.01</span>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a><span class="n">max_grad_norm</span> <span class="o">=</span> <span class="mf">1.0</span>
</span></code></pre></div></p>
<p><strong>Diffusion-Specific</strong>:
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="n">noise_scheduler</span> <span class="o">=</span> <span class="s2">&quot;DDPM&quot;</span>  <span class="c1"># Denoising Diffusion Probabilistic Model</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="n">num_train_timesteps</span> <span class="o">=</span> <span class="mi">1000</span>  <span class="c1"># Stable Diffusion default</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="n">beta_schedule</span> <span class="o">=</span> <span class="s2">&quot;scaled_linear&quot;</span>  <span class="c1"># Noise schedule</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="n">prediction_type</span> <span class="o">=</span> <span class="s2">&quot;epsilon&quot;</span>  <span class="c1"># Predict noise (vs velocity or x0)</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="n">snr_gamma</span> <span class="o">=</span> <span class="mf">5.0</span>  <span class="c1"># Signal-to-noise ratio weighting (improves quality)</span>
</span></code></pre></div></p>
<p><strong>Class Diversity Loss</strong> (FairSkin-specific):
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="n">lambda_diversity</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Weight for diversity loss</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="n">diversity_metric</span> <span class="o">=</span> <span class="s2">&quot;cosine_distance&quot;</span>  <span class="c1"># vs L2 distance</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="n">sample_pool_size</span> <span class="o">=</span> <span class="mi">16</span>  <span class="c1"># Number of embeddings to compare</span>
</span></code></pre></div></p>
<hr />
<h2 id="3-inference-pipeline">3. Inference Pipeline<a class="headerlink" href="#3-inference-pipeline" title="Permanent link">&para;</a></h2>
<h3 id="31-generation-protocol">3.1 Generation Protocol<a class="headerlink" href="#31-generation-protocol" title="Permanent link">&para;</a></h3>
<p><strong>Single Image Generation</strong>:
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">diffusers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StableDiffusionPipeline</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="c1"># Load fine-tuned model</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a><span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;CompVis/stable-diffusion-v1-5&quot;</span>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a><span class="n">pipe</span> <span class="o">=</span> <span class="n">StableDiffusionPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>    <span class="n">model_id</span><span class="p">,</span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>  <span class="c1"># Half precision (2x faster, -50% VRAM)</span>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a><span class="c1"># Load LoRA weights</span>
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a><span class="n">pipe</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">load_attn_procs</span><span class="p">(</span><span class="s2">&quot;path/to/lora_weights&quot;</span><span class="p">)</span>
</span><span id="__span-4-13"><a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>
</span><span id="__span-4-14"><a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a><span class="c1"># Load custom tokens</span>
</span><span id="__span-4-15"><a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a><span class="n">pipe</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">([</span><span class="s2">&quot;&lt;melanoma-FST-VI&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;nevus-FST-I&gt;&quot;</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span>
</span><span id="__span-4-16"><a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a><span class="n">pipe</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pipe</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">))</span>
</span><span id="__span-4-17"><a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a><span class="n">pipe</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;path/to/token_embeddings.pt&quot;</span><span class="p">))</span>
</span><span id="__span-4-18"><a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>
</span><span id="__span-4-19"><a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a><span class="c1"># Generate image</span>
</span><span id="__span-4-20"><a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a><span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;A dermoscopic image of melanoma on Fitzpatrick skin type VI, high quality&quot;</span>
</span><span id="__span-4-21"><a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a><span class="n">negative_prompt</span> <span class="o">=</span> <span class="s2">&quot;blurry, low quality, text, watermark, duplicated&quot;</span>
</span><span id="__span-4-22"><a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a>
</span><span id="__span-4-23"><a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a><span class="n">image</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
</span><span id="__span-4-24"><a id="__codelineno-4-24" name="__codelineno-4-24" href="#__codelineno-4-24"></a>    <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
</span><span id="__span-4-25"><a id="__codelineno-4-25" name="__codelineno-4-25" href="#__codelineno-4-25"></a>    <span class="n">negative_prompt</span><span class="o">=</span><span class="n">negative_prompt</span><span class="p">,</span>
</span><span id="__span-4-26"><a id="__codelineno-4-26" name="__codelineno-4-26" href="#__codelineno-4-26"></a>    <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>  <span class="c1"># Trade-off: 20 (fast, lower quality), 100 (slow, best)</span>
</span><span id="__span-4-27"><a id="__codelineno-4-27" name="__codelineno-4-27" href="#__codelineno-4-27"></a>    <span class="n">guidance_scale</span><span class="o">=</span><span class="mf">7.5</span><span class="p">,</span>  <span class="c1"># Classifier-free guidance (higher = more prompt adherence)</span>
</span><span id="__span-4-28"><a id="__codelineno-4-28" name="__codelineno-4-28" href="#__codelineno-4-28"></a>    <span class="n">height</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</span><span id="__span-4-29"><a id="__codelineno-4-29" name="__codelineno-4-29" href="#__codelineno-4-29"></a>    <span class="n">width</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</span><span id="__span-4-30"><a id="__codelineno-4-30" name="__codelineno-4-30" href="#__codelineno-4-30"></a><span class="p">)</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></code></pre></div></p>
<p><strong>Batch Generation</strong> (for 60k synthetic dataset):
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="c1"># Configuration</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="n">target_images</span> <span class="o">=</span> <span class="mi">60000</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="n">diagnoses</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;MEL&quot;</span><span class="p">,</span> <span class="s2">&quot;NV&quot;</span><span class="p">,</span> <span class="s2">&quot;BCC&quot;</span><span class="p">,</span> <span class="s2">&quot;AK&quot;</span><span class="p">,</span> <span class="s2">&quot;BKL&quot;</span><span class="p">,</span> <span class="s2">&quot;DF&quot;</span><span class="p">,</span> <span class="s2">&quot;VASC&quot;</span><span class="p">]</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span class="n">fst_classes</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;I&quot;</span><span class="p">,</span> <span class="s2">&quot;II&quot;</span><span class="p">,</span> <span class="s2">&quot;III&quot;</span><span class="p">,</span> <span class="s2">&quot;IV&quot;</span><span class="p">,</span> <span class="s2">&quot;V&quot;</span><span class="p">,</span> <span class="s2">&quot;VI&quot;</span><span class="p">]</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a><span class="c1"># Balanced sampling: Oversample FST V-VI</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a><span class="n">fst_distribution</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>    <span class="s2">&quot;I&quot;</span><span class="p">:</span> <span class="mf">0.10</span><span class="p">,</span> <span class="s2">&quot;II&quot;</span><span class="p">:</span> <span class="mf">0.10</span><span class="p">,</span> <span class="s2">&quot;III&quot;</span><span class="p">:</span> <span class="mf">0.15</span><span class="p">,</span>  <span class="c1"># 35% light tones</span>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>    <span class="s2">&quot;IV&quot;</span><span class="p">:</span> <span class="mf">0.15</span><span class="p">,</span>                           <span class="c1"># 15% intermediate</span>
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>    <span class="s2">&quot;V&quot;</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">,</span> <span class="s2">&quot;VI&quot;</span><span class="p">:</span> <span class="mf">0.25</span>                 <span class="c1"># 50% dark tones (vs &lt;5% in original)</span>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a><span class="p">}</span>
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a>
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a><span class="c1"># Generate with quality filtering</span>
</span><span id="__span-5-14"><a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a><span class="n">high_quality_images</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-5-15"><a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a><span class="k">for</span> <span class="n">diagnosis</span> <span class="ow">in</span> <span class="n">diagnoses</span><span class="p">:</span>
</span><span id="__span-5-16"><a id="__codelineno-5-16" name="__codelineno-5-16" href="#__codelineno-5-16"></a>    <span class="k">for</span> <span class="n">fst</span> <span class="ow">in</span> <span class="n">fst_classes</span><span class="p">:</span>
</span><span id="__span-5-17"><a id="__codelineno-5-17" name="__codelineno-5-17" href="#__codelineno-5-17"></a>        <span class="n">num_images</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">target_images</span> <span class="o">*</span> <span class="n">fst_distribution</span><span class="p">[</span><span class="n">fst</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">diagnoses</span><span class="p">))</span>
</span><span id="__span-5-18"><a id="__codelineno-5-18" name="__codelineno-5-18" href="#__codelineno-5-18"></a>
</span><span id="__span-5-19"><a id="__codelineno-5-19" name="__codelineno-5-19" href="#__codelineno-5-19"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_images</span> <span class="o">*</span> <span class="mf">1.5</span><span class="p">):</span>  <span class="c1"># Generate 50% extra for filtering</span>
</span><span id="__span-5-20"><a id="__codelineno-5-20" name="__codelineno-5-20" href="#__codelineno-5-20"></a>            <span class="n">image</span> <span class="o">=</span> <span class="n">generate_image</span><span class="p">(</span><span class="n">diagnosis</span><span class="p">,</span> <span class="n">fst</span><span class="p">)</span>
</span><span id="__span-5-21"><a id="__codelineno-5-21" name="__codelineno-5-21" href="#__codelineno-5-21"></a>
</span><span id="__span-5-22"><a id="__codelineno-5-22" name="__codelineno-5-22" href="#__codelineno-5-22"></a>            <span class="c1"># Quality checks (see section 3.2)</span>
</span><span id="__span-5-23"><a id="__codelineno-5-23" name="__codelineno-5-23" href="#__codelineno-5-23"></a>            <span class="k">if</span> <span class="n">passes_quality_checks</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
</span><span id="__span-5-24"><a id="__codelineno-5-24" name="__codelineno-5-24" href="#__codelineno-5-24"></a>                <span class="n">high_quality_images</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">image</span><span class="p">,</span> <span class="n">diagnosis</span><span class="p">,</span> <span class="n">fst</span><span class="p">))</span>
</span><span id="__span-5-25"><a id="__codelineno-5-25" name="__codelineno-5-25" href="#__codelineno-5-25"></a>                <span class="k">if</span> <span class="nb">len</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">high_quality_images</span> <span class="k">if</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">fst</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="n">num_images</span><span class="p">:</span>
</span><span id="__span-5-26"><a id="__codelineno-5-26" name="__codelineno-5-26" href="#__codelineno-5-26"></a>                    <span class="k">break</span>
</span><span id="__span-5-27"><a id="__codelineno-5-27" name="__codelineno-5-27" href="#__codelineno-5-27"></a>
</span><span id="__span-5-28"><a id="__codelineno-5-28" name="__codelineno-5-28" href="#__codelineno-5-28"></a><span class="c1"># Result: 60,000 high-quality synthetic images with balanced FST distribution</span>
</span></code></pre></div></p>
<h3 id="32-quality-validation">3.2 Quality Validation<a class="headerlink" href="#32-quality-validation" title="Permanent link">&para;</a></h3>
<p><strong>Automatic Quality Metrics</strong>:</p>
<ol>
<li><strong>FID (Frechet Inception Distance)</strong>: &lt;20 (threshold from literature)</li>
<li>Measures distribution similarity: synthetic vs real images</li>
<li>Calculate per FST class: FID_FST-VI should be &lt;25 (slightly higher acceptable for rare groups)</li>
<li>
<p><strong>Implementation</strong>: Use <code>pytorch-fid</code> library, 2048-dim Inception-v3 features</p>
</li>
<li>
<p><strong>LPIPS (Learned Perceptual Image Patch Similarity)</strong>: &lt;0.15 (vs real images)</p>
</li>
<li>Measures perceptual similarity using deep features</li>
<li>Lower = more realistic (but not identical, which would indicate memorization)</li>
<li>
<p><strong>Implementation</strong>: Use <code>lpips</code> library, AlexNet or VGG backbone</p>
</li>
<li>
<p><strong>Classifier Confidence</strong> (diagnosis prediction):</p>
</li>
<li>Train ResNet50 on real data, evaluate on synthetic</li>
<li>Synthetic images should yield confident predictions (softmax &gt;0.7)</li>
<li>
<p>Low confidence = unrealistic lesion morphology</p>
</li>
<li>
<p><strong>Diversity Score</strong> (intra-class):</p>
</li>
<li>CLIP embeddings for all synthetic images of same (diagnosis, FST)</li>
<li>Average pairwise cosine distance: &gt;0.3 (avoid mode collapse)</li>
<li>Low diversity = model generating identical images</li>
</ol>
<p><strong>Expert Dermatologist Review</strong> (Quality Assurance):
- Sample 500 synthetic images (stratified by diagnosis × FST)
- 3 dermatologists rate each image (blinded, mixed with real images)
- Rating scale: 1-7 (1=clearly fake, 4=uncertain, 7=clinically realistic)
- <strong>Acceptance criteria</strong>: Mean score &gt;5.0, &lt;10% images rated &lt;3</p>
<p><strong>Quality Filtering Pipeline</strong>:
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">passes_quality_checks</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">diagnosis</span><span class="p">,</span> <span class="n">fst</span><span class="p">):</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>    <span class="c1"># 1. Resolution check</span>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>    <span class="k">if</span> <span class="n">image</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">):</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>        <span class="k">return</span> <span class="kc">False</span>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>    <span class="c1"># 2. Brightness check (avoid pure black/white)</span>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>    <span class="n">mean_brightness</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>    <span class="k">if</span> <span class="n">mean_brightness</span> <span class="o">&lt;</span> <span class="mf">0.1</span> <span class="ow">or</span> <span class="n">mean_brightness</span> <span class="o">&gt;</span> <span class="mf">0.9</span><span class="p">:</span>
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a>        <span class="k">return</span> <span class="kc">False</span>
</span><span id="__span-6-10"><a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a>
</span><span id="__span-6-11"><a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a>    <span class="c1"># 3. FID check (per-image approximation using nearest neighbor)</span>
</span><span id="__span-6-12"><a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a>    <span class="n">fid_score</span> <span class="o">=</span> <span class="n">compute_single_image_fid</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">real_dataset_fst</span><span class="o">=</span><span class="n">fst</span><span class="p">)</span>
</span><span id="__span-6-13"><a id="__codelineno-6-13" name="__codelineno-6-13" href="#__codelineno-6-13"></a>    <span class="k">if</span> <span class="n">fid_score</span> <span class="o">&gt;</span> <span class="mi">30</span><span class="p">:</span>
</span><span id="__span-6-14"><a id="__codelineno-6-14" name="__codelineno-6-14" href="#__codelineno-6-14"></a>        <span class="k">return</span> <span class="kc">False</span>
</span><span id="__span-6-15"><a id="__codelineno-6-15" name="__codelineno-6-15" href="#__codelineno-6-15"></a>
</span><span id="__span-6-16"><a id="__codelineno-6-16" name="__codelineno-6-16" href="#__codelineno-6-16"></a>    <span class="c1"># 4. LPIPS check (vs 10 random real images of same FST)</span>
</span><span id="__span-6-17"><a id="__codelineno-6-17" name="__codelineno-6-17" href="#__codelineno-6-17"></a>    <span class="n">lpips_scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">compute_lpips</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">real_img</span><span class="p">)</span> <span class="k">for</span> <span class="n">real_img</span> <span class="ow">in</span> <span class="n">sample_real_images</span><span class="p">(</span><span class="n">fst</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">)]</span>
</span><span id="__span-6-18"><a id="__codelineno-6-18" name="__codelineno-6-18" href="#__codelineno-6-18"></a>    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">lpips_scores</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.2</span><span class="p">:</span>
</span><span id="__span-6-19"><a id="__codelineno-6-19" name="__codelineno-6-19" href="#__codelineno-6-19"></a>        <span class="k">return</span> <span class="kc">False</span>
</span><span id="__span-6-20"><a id="__codelineno-6-20" name="__codelineno-6-20" href="#__codelineno-6-20"></a>
</span><span id="__span-6-21"><a id="__codelineno-6-21" name="__codelineno-6-21" href="#__codelineno-6-21"></a>    <span class="c1"># 5. Classifier confidence check</span>
</span><span id="__span-6-22"><a id="__codelineno-6-22" name="__codelineno-6-22" href="#__codelineno-6-22"></a>    <span class="n">prediction</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</span><span id="__span-6-23"><a id="__codelineno-6-23" name="__codelineno-6-23" href="#__codelineno-6-23"></a>    <span class="k">if</span> <span class="n">prediction</span><span class="p">[</span><span class="s2">&quot;confidence&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.6</span><span class="p">:</span>
</span><span id="__span-6-24"><a id="__codelineno-6-24" name="__codelineno-6-24" href="#__codelineno-6-24"></a>        <span class="k">return</span> <span class="kc">False</span>
</span><span id="__span-6-25"><a id="__codelineno-6-25" name="__codelineno-6-25" href="#__codelineno-6-25"></a>
</span><span id="__span-6-26"><a id="__codelineno-6-26" name="__codelineno-6-26" href="#__codelineno-6-26"></a>    <span class="c1"># 6. Diversity check (vs previous synthetic images)</span>
</span><span id="__span-6-27"><a id="__codelineno-6-27" name="__codelineno-6-27" href="#__codelineno-6-27"></a>    <span class="k">if</span> <span class="n">is_too_similar_to_existing</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">existing_synthetic_images</span><span class="p">):</span>
</span><span id="__span-6-28"><a id="__codelineno-6-28" name="__codelineno-6-28" href="#__codelineno-6-28"></a>        <span class="k">return</span> <span class="kc">False</span>
</span><span id="__span-6-29"><a id="__codelineno-6-29" name="__codelineno-6-29" href="#__codelineno-6-29"></a>
</span><span id="__span-6-30"><a id="__codelineno-6-30" name="__codelineno-6-30" href="#__codelineno-6-30"></a>    <span class="k">return</span> <span class="kc">True</span>
</span></code></pre></div></p>
<hr />
<h2 id="4-integration-with-training-loop">4. Integration with Training Loop<a class="headerlink" href="#4-integration-with-training-loop" title="Permanent link">&para;</a></h2>
<h3 id="41-synthetic-real-data-mixing">4.1 Synthetic + Real Data Mixing<a class="headerlink" href="#41-synthetic-real-data-mixing" title="Permanent link">&para;</a></h3>
<p><strong>Three Strategies</strong> (from literature):</p>
<p><strong>Strategy 1: Pre-Generate Static Dataset</strong> (Recommended for Phase 2)
- Generate 60,000 synthetic images BEFORE classifier training
- Store in disk (lossless PNG format)
- Mix with real data during DataLoader sampling</p>
<p><strong>Advantages</strong>:
- Fast training (no generation overhead during epochs)
- Reproducible experiments (same synthetic dataset)
- Easy quality control (filter before training)</p>
<p><strong>Disadvantages</strong>:
- Large storage (60k × 512×512×3 × 8bit = ~47GB)
- No dynamic adaptation (fixed synthetic dataset)</p>
<p><strong>Implementation</strong>:
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="c1"># Pre-generation script (run once)</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="n">python</span> <span class="n">scripts</span><span class="o">/</span><span class="n">generate_fairskin_dataset</span><span class="o">.</span><span class="n">py</span> \
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>    <span class="o">--</span><span class="n">num_images</span> <span class="mi">60000</span> \
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>    <span class="o">--</span><span class="n">output_dir</span> <span class="n">data</span><span class="o">/</span><span class="n">synthetic</span><span class="o">/</span><span class="n">fairskin</span> \
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>    <span class="o">--</span><span class="n">fst_distribution</span> <span class="n">balanced</span> \
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>    <span class="o">--</span><span class="n">quality_threshold</span> <span class="n">high</span>
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a><span class="c1"># Training script (use mixed dataset)</span>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConcatDataset</span>
</span><span id="__span-7-10"><a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a>
</span><span id="__span-7-11"><a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a><span class="n">real_dataset</span> <span class="o">=</span> <span class="n">FitzpatrickDataset</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">&quot;data/real&quot;</span><span class="p">)</span>
</span><span id="__span-7-12"><a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a><span class="n">synthetic_dataset</span> <span class="o">=</span> <span class="n">FitzpatrickDataset</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">&quot;data/synthetic/fairskin&quot;</span><span class="p">)</span>
</span><span id="__span-7-13"><a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a>
</span><span id="__span-7-14"><a id="__codelineno-7-14" name="__codelineno-7-14" href="#__codelineno-7-14"></a><span class="c1"># Weighted sampling: FST-dependent synthetic ratio</span>
</span><span id="__span-7-15"><a id="__codelineno-7-15" name="__codelineno-7-15" href="#__codelineno-7-15"></a><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">WeightedMixedDataset</span><span class="p">(</span>
</span><span id="__span-7-16"><a id="__codelineno-7-16" name="__codelineno-7-16" href="#__codelineno-7-16"></a>    <span class="n">real</span><span class="o">=</span><span class="n">real_dataset</span><span class="p">,</span>
</span><span id="__span-7-17"><a id="__codelineno-7-17" name="__codelineno-7-17" href="#__codelineno-7-17"></a>    <span class="n">synthetic</span><span class="o">=</span><span class="n">synthetic_dataset</span><span class="p">,</span>
</span><span id="__span-7-18"><a id="__codelineno-7-18" name="__codelineno-7-18" href="#__codelineno-7-18"></a>    <span class="n">synthetic_ratio_by_fst</span><span class="o">=</span><span class="p">{</span>
</span><span id="__span-7-19"><a id="__codelineno-7-19" name="__codelineno-7-19" href="#__codelineno-7-19"></a>        <span class="s2">&quot;I&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;II&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;III&quot;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span>  <span class="c1"># 20-30% synthetic for light tones</span>
</span><span id="__span-7-20"><a id="__codelineno-7-20" name="__codelineno-7-20" href="#__codelineno-7-20"></a>        <span class="s2">&quot;IV&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>                         <span class="c1"># 50% for intermediate</span>
</span><span id="__span-7-21"><a id="__codelineno-7-21" name="__codelineno-7-21" href="#__codelineno-7-21"></a>        <span class="s2">&quot;V&quot;</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">,</span> <span class="s2">&quot;VI&quot;</span><span class="p">:</span> <span class="mf">0.8</span>                <span class="c1"># 70-80% for dark tones (scarce real data)</span>
</span><span id="__span-7-22"><a id="__codelineno-7-22" name="__codelineno-7-22" href="#__codelineno-7-22"></a>    <span class="p">}</span>
</span><span id="__span-7-23"><a id="__codelineno-7-23" name="__codelineno-7-23" href="#__codelineno-7-23"></a><span class="p">)</span>
</span></code></pre></div></p>
<p><strong>Strategy 2: On-the-Fly Generation</strong> (Advanced, Phase 3+)
- Generate synthetic images during training (as augmentation)
- Cache last N generated images to avoid redundant generation</p>
<p><strong>Advantages</strong>:
- No storage overhead
- Dynamic adaptation (generate images model struggles with)
- Infinite dataset size (never see same synthetic image twice)</p>
<p><strong>Disadvantages</strong>:
- Slow training (3-6s generation time per image)
- Requires powerful GPU for simultaneous generation + training
- Harder to debug (non-reproducible)</p>
<p><strong>Strategy 3: Hybrid</strong> (Best of Both)
- Pre-generate 30k synthetic images (core dataset)
- Generate additional 5-10% on-the-fly (for hard examples)
- Use classifier loss to guide generation: "Generate more FST VI melanoma images, current model struggles"</p>
<h3 id="42-training-protocol">4.2 Training Protocol<a class="headerlink" href="#42-training-protocol" title="Permanent link">&para;</a></h3>
<p><strong>Phase 1: Pre-train on Synthetic (Optional)</strong>
- Train ResNet50 on 60k synthetic images ONLY
- Goal: Learn FST-invariant representations
- 50 epochs, standard hyperparameters
- <strong>Expected</strong>: Lower accuracy (85-88%) but better fairness (AUROC gap &lt;6%)</p>
<p><strong>Phase 2: Fine-tune on Real</strong>
- Initialize from Phase 1 checkpoint
- Train on mixed dataset (real + synthetic)
- 100 epochs, lower learning rate (1e-4 → 1e-5 after 50 epochs)
- <strong>Expected</strong>: High accuracy (91-93%) + maintained fairness</p>
<p><strong>Phase 3: Domain Adaptation</strong> (if synthetic artifacts detected)
- Use domain adversarial training (DANN)
- Auxiliary discriminator: Predict real vs synthetic
- Maximize classification accuracy, minimize domain predictability
- <strong>Expected</strong>: Further reduce AUROC gap (-1-2% improvement)</p>
<hr />
<h2 id="5-implementation-timeline">5. Implementation Timeline<a class="headerlink" href="#5-implementation-timeline" title="Permanent link">&para;</a></h2>
<h3 id="week-1-setup-dataset-preparation">Week 1: Setup &amp; Dataset Preparation<a class="headerlink" href="#week-1-setup-dataset-preparation" title="Permanent link">&para;</a></h3>
<ul>
<li>Day 1-2: Install Hugging Face Diffusers, PyTorch, dependencies</li>
<li>Day 3-4: Download Fitzpatrick17k, DDI, HAM10000</li>
<li>Day 5: Preprocess datasets (resize, normalize, hair removal)</li>
<li>Day 6-7: Create training splits, verify FST distributions</li>
</ul>
<p><strong>Deliverables</strong>: <code>data/processed/fitzpatrick17k/</code>, <code>data/processed/ddi/</code>, preprocessing scripts</p>
<h3 id="week-2-textual-inversion">Week 2: Textual Inversion<a class="headerlink" href="#week-2-textual-inversion" title="Permanent link">&para;</a></h3>
<ul>
<li>Day 1-2: Implement textual inversion training script</li>
<li>Day 3: Train token embeddings (2000 steps, ~4 hours)</li>
<li>Day 4: Validate: Generate images from text prompts, qualitative review</li>
<li>Day 5-7: Iterate: Adjust learning rate, add more tokens if needed</li>
</ul>
<p><strong>Deliverables</strong>: <code>checkpoints/textual_inversion/token_embeddings.pt</code>, validation images</p>
<h3 id="week-3-4-lora-training">Week 3-4: LoRA Training<a class="headerlink" href="#week-3-4-lora-training" title="Permanent link">&para;</a></h3>
<ul>
<li>Day 1-2: Implement LoRA training script (integrate with textual inversion)</li>
<li>Day 3-5: Train LoRA adapters (10k steps, ~20 hours)</li>
<li>Day 6-7: Validate: Generate 100 images per (diagnosis × FST), compute FID/LPIPS</li>
<li>Day 8-10: Iterate: Adjust rank, alpha, learning rate if quality insufficient</li>
</ul>
<p><strong>Deliverables</strong>: <code>checkpoints/lora/lora_weights.pt</code>, quality metrics report</p>
<h3 id="week-5-batch-generation">Week 5: Batch Generation<a class="headerlink" href="#week-5-batch-generation" title="Permanent link">&para;</a></h3>
<ul>
<li>Day 1-2: Implement batch generation script with quality filtering</li>
<li>Day 3-5: Generate 60k synthetic images (~120 hours GPU time, run overnight/weekend)</li>
<li>Day 6-7: Expert review: Sample 500 images, dermatologist rating</li>
</ul>
<p><strong>Deliverables</strong>: <code>data/synthetic/fairskin/</code> (60k images), quality report</p>
<h3 id="week-6-integration-training">Week 6: Integration &amp; Training<a class="headerlink" href="#week-6-integration-training" title="Permanent link">&para;</a></h3>
<ul>
<li>Day 1-2: Implement mixed dataset loader (real + synthetic)</li>
<li>Day 3-7: Train ResNet50 classifier with mixed data (100 epochs, ~48 hours)</li>
<li>Evaluate: AUROC per FST, compare to baseline</li>
</ul>
<p><strong>Deliverables</strong>: <code>models/fairskin_resnet50.pth</code>, fairness metrics report</p>
<p><strong>Total Time: 6 weeks (42 days)</strong>
- GPU-intensive tasks: ~170 hours (7 days continuous GPU usage)
- Human time: ~40 hours (1 week full-time equivalent)</p>
<hr />
<h2 id="6-pre-trained-models-open-source-resources">6. Pre-Trained Models &amp; Open-Source Resources<a class="headerlink" href="#6-pre-trained-models-open-source-resources" title="Permanent link">&para;</a></h2>
<h3 id="61-available-checkpoints">6.1 Available Checkpoints<a class="headerlink" href="#61-available-checkpoints" title="Permanent link">&para;</a></h3>
<p><strong>Option 1: janet-sw/skin-diff</strong> (GitHub)
- Repository: https://github.com/janet-sw/skin-diff
- Paper: "From Majority to Minority" (MICCAI ISIC Workshop 2024, Honorable Mention)
- Base model: Stable Diffusion v1.5
- Pre-trained: Textual Inversion + LoRA on HAM10000 + ISIC 2019
- <strong>Pros</strong>: Ready to use, validated in peer-reviewed work
- <strong>Cons</strong>: Trained on tone-imbalanced datasets (may need re-training)
- <strong>License</strong>: Not specified in repo (contact authors)</p>
<p><strong>Option 2: Train from Scratch</strong> (Recommended)
- Use Stable Diffusion v1.5 as base (open license: CreativeML Open RAIL-M)
- Train on Fitzpatrick17k + DDI (FST-diverse datasets)
- Full control over hyperparameters, data distribution
- <strong>Estimated time</strong>: 6 weeks (see section 5)</p>
<p><strong>Option 3: Pre-trained Dermatology Models</strong> (Hugging Face Hub)
- Search query: "dermatology diffusion" OR "skin lesion generation"
- As of 2025-01, no dedicated dermatology diffusion models on Hub
- General Stable Diffusion v1.5/v2.1 models available
- <strong>Recommendation</strong>: Start with SD v1.5, fine-tune for dermatology</p>
<h3 id="62-alternative-architectures-future-work">6.2 Alternative Architectures (Future Work)<a class="headerlink" href="#62-alternative-architectures-future-work" title="Permanent link">&para;</a></h3>
<p><strong>DermDiff</strong> (Hypothetical, if released):
- Specialized dermatology diffusion model
- Pre-trained on 100k+ dermoscopic images
- FST-aware conditioning built-in
- <strong>If released</strong>: Use as base instead of SD v1.5 (faster training, better quality)</p>
<p><strong>Latent Diffusion with MedCLIP</strong>:
- Replace CLIP text encoder with MedCLIP (medical domain-specific)
- Better understanding of clinical terminology
- <strong>Implementation</strong>: Swap <code>text_encoder</code> in Diffusers pipeline
- <strong>Expected</strong>: +2-3% generation quality (FID improvement)</p>
<hr />
<h2 id="7-key-questions-answers">7. Key Questions &amp; Answers<a class="headerlink" href="#7-key-questions-answers" title="Permanent link">&para;</a></h2>
<h3 id="q1-can-we-use-pre-trained-dermatology-diffusion-models">Q1: Can we use pre-trained dermatology diffusion models?<a class="headerlink" href="#q1-can-we-use-pre-trained-dermatology-diffusion-models" title="Permanent link">&para;</a></h3>
<p><strong>Answer</strong>: As of 2025-01, no pre-trained dermatology-specific diffusion models are publicly available on Hugging Face Hub. The janet-sw/skin-diff repository provides LoRA weights, but these were trained on tone-imbalanced datasets (HAM10000, ISIC 2019). <strong>Recommendation</strong>: Start with Stable Diffusion v1.5, fine-tune on Fitzpatrick17k + DDI for FST diversity.</p>
<h3 id="q2-whats-the-minimum-viable-dataset-for-lora-training">Q2: What's the minimum viable dataset for LoRA training?<a class="headerlink" href="#q2-whats-the-minimum-viable-dataset-for-lora-training" title="Permanent link">&para;</a></h3>
<p><strong>Answer</strong>: 500-1000 images per diagnosis class, with minimum 100 images per FST class. DDI (656 images, 34% FST V-VI) is sufficient for initial experiments. For production, combine Fitzpatrick17k (16,577 images) + DDI (656 images) = <strong>17,233 images total</strong>, which enables robust training.</p>
<h3 id="q3-how-to-ensure-synthetic-quality-fid-20-lpips-01">Q3: How to ensure synthetic quality (FID &lt;20, LPIPS &lt;0.1)?<a class="headerlink" href="#q3-how-to-ensure-synthetic-quality-fid-20-lpips-01" title="Permanent link">&para;</a></h3>
<p><strong>Answer</strong>: Multi-pronged approach:
1. <strong>Data quality</strong>: Use high-resolution (512x512+), clinician-annotated training data
2. <strong>Hyperparameter tuning</strong>: Rank 16, alpha 32, learning rate 1e-4 (see section 2.3)
3. <strong>Class diversity loss</strong>: Lambda 0.1 (prevents mode collapse)
4. <strong>Quality filtering</strong>: Generate 1.5x target images, keep only high-quality (see section 3.2)
5. <strong>Expert review</strong>: Dermatologist rating &gt;5/7 on 500-image sample</p>
<p><strong>Empirical benchmarks</strong>:
- janet-sw/skin-diff: FID 18.3 (HAM10000 test set)
- FairSkin paper: FID 16.7 (Fitzpatrick17k)
- <strong>Target</strong>: FID &lt;20 per FST class (FST VI may reach ~22-25, acceptable)</p>
<h3 id="q4-pre-generate-60k-images-or-on-the-fly-during-training">Q4: Pre-generate 60k images or on-the-fly during training?<a class="headerlink" href="#q4-pre-generate-60k-images-or-on-the-fly-during-training" title="Permanent link">&para;</a></h3>
<p><strong>Answer</strong>: <strong>Pre-generate for Phase 2</strong> (production hardening in Phase 4 can explore on-the-fly).</p>
<p><strong>Rationale</strong>:
- Phase 2 focus: Validate fairness improvement (need reproducible experiments)
- Pre-generation: Fixed dataset enables direct comparison across runs
- Storage: 47GB (negligible on modern systems)
- Training speed: No generation overhead (faster epoch time)</p>
<p><strong>On-the-fly for Phase 3+</strong> (if benefits justify complexity):
- Dynamic adaptation: Generate images model struggles with
- Infinite diversity: Never repeat synthetic image
- <strong>Implementation complexity</strong>: Requires multi-GPU setup (1 for generation, 1+ for training)</p>
<hr />
<h2 id="8-risk-mitigation">8. Risk Mitigation<a class="headerlink" href="#8-risk-mitigation" title="Permanent link">&para;</a></h2>
<h3 id="risk-1-low-synthetic-quality-fid-30">Risk 1: Low Synthetic Quality (FID &gt;30)<a class="headerlink" href="#risk-1-low-synthetic-quality-fid-30" title="Permanent link">&para;</a></h3>
<p><strong>Mitigation</strong>:
- Use higher-quality training data (DDI vs HAM10000)
- Increase LoRA rank (16 → 32) and training steps (10k → 20k)
- Add classifier-guided generation (use pre-trained ResNet to filter bad images)</p>
<h3 id="risk-2-mode-collapse-all-fst-vi-images-look-identical">Risk 2: Mode Collapse (All FST VI Images Look Identical)<a class="headerlink" href="#risk-2-mode-collapse-all-fst-vi-images-look-identical" title="Permanent link">&para;</a></h3>
<p><strong>Mitigation</strong>:
- Class diversity loss (lambda 0.1-0.2)
- Increase diffusion steps during inference (50 → 100)
- Use temperature scaling in sampling (temperature 0.7-0.9)</p>
<h3 id="risk-3-memorization-synthetic-images-identical-to-training-data">Risk 3: Memorization (Synthetic Images Identical to Training Data)<a class="headerlink" href="#risk-3-memorization-synthetic-images-identical-to-training-data" title="Permanent link">&para;</a></h3>
<p><strong>Mitigation</strong>:
- Check LPIPS &lt;0.1 vs training set (high similarity = memorization)
- Use LoRA dropout 0.1 (regularization)
- Limit training steps if overfitting detected (reduce 10k → 5k)</p>
<h3 id="risk-4-domain-shift-classifier-fails-on-synthetic-images">Risk 4: Domain Shift (Classifier Fails on Synthetic Images)<a class="headerlink" href="#risk-4-domain-shift-classifier-fails-on-synthetic-images" title="Permanent link">&para;</a></h3>
<p><strong>Mitigation</strong>:
- Domain adversarial training (DANN): Make classifier agnostic to real vs synthetic
- Gradually increase synthetic ratio (start 30%, increase to 80% over epochs)
- Hybrid strategy: Always keep 20% real data in batches</p>
<h3 id="risk-5-ethical-concerns-synthetic-medical-data">Risk 5: Ethical Concerns (Synthetic Medical Data)<a class="headerlink" href="#risk-5-ethical-concerns-synthetic-medical-data" title="Permanent link">&para;</a></h3>
<p><strong>Mitigation</strong>:
- Expert validation: Dermatologist review mandatory (500+ images)
- Model card transparency: Disclose synthetic data usage, proportions
- Clinical trial: Validate on real-world prospective data (Phase 5)
- Regulatory guidance: Consult FDA/EMA on synthetic data acceptability</p>
<hr />
<h2 id="9-success-criteria">9. Success Criteria<a class="headerlink" href="#9-success-criteria" title="Permanent link">&para;</a></h2>
<h3 id="technical-metrics">Technical Metrics<a class="headerlink" href="#technical-metrics" title="Permanent link">&para;</a></h3>
<ul>
<li>FID &lt;20 per FST class (FST VI: &lt;25 acceptable)</li>
<li>LPIPS &lt;0.15 (vs real images of same FST)</li>
<li>Classifier confidence &gt;0.7 on synthetic images</li>
<li>Intra-class diversity &gt;0.3 (CLIP embedding distance)</li>
</ul>
<h3 id="fairness-impact">Fairness Impact<a class="headerlink" href="#fairness-impact" title="Permanent link">&para;</a></h3>
<ul>
<li>AUROC gap reduction: 15-20% (baseline) → 8-12% (Phase 2) = <strong>40-60% improvement</strong></li>
<li>Expected AUROC gain for FST V-VI: +18-21% (literature benchmark)</li>
<li>EOD reduction: &gt;30% (from FairSkin data augmentation alone)</li>
</ul>
<h3 id="qualitative-validation">Qualitative Validation<a class="headerlink" href="#qualitative-validation" title="Permanent link">&para;</a></h3>
<ul>
<li>Dermatologist rating: Mean &gt;5.0/7.0 (500-image sample)</li>
<li>Acceptance rate: &gt;90% images rated ≥4/7</li>
<li>Rejection rate: &lt;10% images rated &lt;3/7 (clearly synthetic)</li>
</ul>
<h3 id="operational">Operational<a class="headerlink" href="#operational" title="Permanent link">&para;</a></h3>
<ul>
<li>Generation time: &lt;6s per image (RTX 3090, 50 steps)</li>
<li>Storage: &lt;50GB (60k images, compressed PNG)</li>
<li>Integration time: &lt;1 week (implement mixed dataset loader)</li>
</ul>
<hr />
<h2 id="10-references">10. References<a class="headerlink" href="#10-references" title="Permanent link">&para;</a></h2>
<p><strong>Primary Paper</strong>:
- Ju, L., et al. (2024). "FairSkin: Fair Diffusion for Skin Disease Image Generation." arXiv:2410.22551</p>
<p><strong>Implementation Reference</strong>:
- janet-sw. (2024). "skin-diff: From Majority to Minority." GitHub. https://github.com/janet-sw/skin-diff</p>
<p><strong>Diffusion Frameworks</strong>:
- Rombach, R., et al. (2022). "High-Resolution Image Synthesis with Latent Diffusion Models." CVPR.
- Hugging Face Diffusers: https://huggingface.co/docs/diffusers</p>
<p><strong>LoRA &amp; Fine-Tuning</strong>:
- Hu, E.J., et al. (2021). "LoRA: Low-Rank Adaptation of Large Language Models." ICLR.
- Gal, R., et al. (2022). "An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion." arXiv:2208.01618</p>
<p><strong>Quality Metrics</strong>:
- Heusel, M., et al. (2017). "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium." NeurIPS. (FID metric)
- Zhang, R., et al. (2018). "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric." CVPR. (LPIPS metric)</p>
<hr />
<p><strong>Document Version</strong>: 1.0
<strong>Last Updated</strong>: 2025-10-13
<strong>Author</strong>: THE DIDACT (Strategic Research Agent)
<strong>Status</strong>: IMPLEMENTATION-READY
<strong>Next Review</strong>: Post-Phase 2 (Week 10)</p>









  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/zhadyz/fairness-skin-cancer-detection" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:abdul.bari8019@coyote.csusb.edu" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4l208 156a48 48 0 0 0 57.6 0l208-156c12.1-9.1 19.2-23.3 19.2-38.4 0-26.5-21.5-48-48-48zM0 196v188c0 35.3 28.7 64 64 64h384c35.3 0 64-28.7 64-64V196L313.6 344.8c-34.1 25.6-81.1 25.6-115.2 0z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "content.code.copy", "content.code.annotate"], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../javascripts/custom.js"></script>
      
    
  </body>
</html>